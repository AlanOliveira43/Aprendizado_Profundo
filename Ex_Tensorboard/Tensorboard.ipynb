{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alan de castro\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alan de castro\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.57.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (3.4.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (4.24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.3.7)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (0.41.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\alan de castro\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alan de castro\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Loss from last step: 2.325\n",
      "Total running accuracy so far: 0.109\n",
      "Step: 100\n",
      "Loss from last step: 0.262\n",
      "Total running accuracy so far: 0.834\n",
      "Step: 200\n",
      "Loss from last step: 0.171\n",
      "Total running accuracy so far: 0.875\n",
      "Step: 300\n",
      "Loss from last step: 0.191\n",
      "Total running accuracy so far: 0.893\n",
      "Step: 400\n",
      "Loss from last step: 0.176\n",
      "Total running accuracy so far: 0.907\n",
      "Step: 500\n",
      "Loss from last step: 0.082\n",
      "Total running accuracy so far: 0.914\n",
      "Step: 600\n",
      "Loss from last step: 0.220\n",
      "Total running accuracy so far: 0.921\n",
      "Step: 700\n",
      "Loss from last step: 0.135\n",
      "Total running accuracy so far: 0.926\n",
      "Step: 800\n",
      "Loss from last step: 0.281\n",
      "Total running accuracy so far: 0.930\n",
      "Step: 900\n",
      "Loss from last step: 0.077\n",
      "Total running accuracy so far: 0.933\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} log/fit is not a directory [Op:CreateSummaryFileWriter] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m callbacks \u001b[39m=\u001b[39m [tensorboard_callback]\n\u001b[0;32m     66\u001b[0m \u001b[39m# Train the model with the callbacks for TensorBoard.\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   6655\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m-> 6656\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} log/fit is not a directory [Op:CreateSummaryFileWriter] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "# Prepare a dataset.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:].reshape(60000, 784).astype('float32') / 255\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Instantiate a simple classification model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(256, activation=tf.nn.relu),\n",
    "  layers.Dense(256, activation=tf.nn.relu),\n",
    "  layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Instantiate a logistic loss function that expects integer targets.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Instantiate an accuracy metric.\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
    "\n",
    "# Prompt the user for an existing log directory.\n",
    "log_dir = input(\"Enter an existing log directory path: \")\n",
    "if not os.path.exists(log_dir):\n",
    "    print(f\"The specified directory '{log_dir}' does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Create a TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Iterate over the batches of the dataset.\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    # Open a GradientTape.\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass.\n",
    "        logits = model(x)\n",
    "        # Loss value for this batch.\n",
    "        loss_value = loss(y, logits)\n",
    "    \n",
    "    # Get gradients of loss wrt the weights.\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "    # Update the weights of our linear layer.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    # Update the running accuracy.\n",
    "    accuracy.update_state(y, logits)\n",
    "\n",
    "    # Logging.\n",
    "    if step % 100 == 0:\n",
    "        print('Step:', step)\n",
    "        print('Loss from last step: %.3f' % loss_value)\n",
    "        print('Total running accuracy so far: %.3f' % accuracy.result())\n",
    "\n",
    "# Add the TensorBoard callback to the training history.\n",
    "callbacks = [tensorboard_callback]\n",
    "\n",
    "# Train the model with the callbacks for TensorBoard.\n",
    "model.fit(dataset, epochs=5, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10564), started 0:00:05 ago. (Use '!kill 10564' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a696f4c6c239ba02\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a696f4c6c239ba02\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss: 2.396, Accuracy: 0.078\n",
      "Step 100: Loss: 0.453, Accuracy: 0.784\n",
      "Step 200: Loss: 0.395, Accuracy: 0.831\n",
      "Step 300: Loss: 0.143, Accuracy: 0.851\n",
      "Step 400: Loss: 0.256, Accuracy: 0.866\n",
      "Step 500: Loss: 0.359, Accuracy: 0.874\n",
      "Step 600: Loss: 0.299, Accuracy: 0.882\n",
      "Step 700: Loss: 0.170, Accuracy: 0.887\n",
      "Step 800: Loss: 0.284, Accuracy: 0.891\n",
      "Step 900: Loss: 0.102, Accuracy: 0.896\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "sparse_mlp_model\\variables is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStep \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m: Loss: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (step, loss, train_accuracy\u001b[39m.\u001b[39mresult()))\n\u001b[0;32m     66\u001b[0m \u001b[39m# Save the model for future use if needed.\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m mlp\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39msparse_mlp_model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     69\u001b[0m \u001b[39m# Start TensorBoard with the following command:\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m# tensorboard --logdir logs/fit\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.makedirs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[0;32m    503\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[39m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mRecursivelyCreateDir(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: sparse_mlp_model\\variables is not a directory"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "import datetime\n",
    "\n",
    "# Define a função do modelo MLP esparso.\n",
    "class SparseMLP(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SparseMLP, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = Dense(128, activation='relu')\n",
    "        self.fc2 = Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Prepare a dataset.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype('float32') / 255, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Create a log directory for TensorBoard.\n",
    "log_dir = \"log/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# A new MLP.\n",
    "mlp = SparseMLP(10)\n",
    "\n",
    "# Loss and optimizer.\n",
    "loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = SGD(learning_rate=0.1)\n",
    "\n",
    "# Define a metric for tracking accuracy.\n",
    "train_accuracy = SparseCategoricalAccuracy()\n",
    "\n",
    "# Training loop.\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass.\n",
    "        logits = mlp(x)\n",
    "\n",
    "        # External loss value for this batch.\n",
    "        loss = loss_fn(y, logits)\n",
    "\n",
    "        # Add the losses created during the forward pass.\n",
    "        loss += sum(mlp.losses)\n",
    "\n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss, mlp.trainable_weights)\n",
    "\n",
    "    # Update the weights of our linear layer.\n",
    "    optimizer.apply_gradients(zip(gradients, mlp.trainable_weights))\n",
    "\n",
    "    # Update the accuracy metric.\n",
    "    train_accuracy.update_state(y, logits)\n",
    "\n",
    "    # Logging.\n",
    "    if step % 100 == 0:\n",
    "        print('Step %d: Loss: %.3f, Accuracy: %.3f' % (step, loss, train_accuracy.result()))\n",
    "\n",
    "# Save the model for future use if needed.\n",
    "mlp.save(\"sparse_mlp_model\")\n",
    "\n",
    "# Start TensorBoard with the following command:\n",
    "# tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19264), started 21:25:24 ago. (Use '!kill 19264' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b788dae719bc3029\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b788dae719bc3029\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2203 - sparse_categorical_accuracy: 0.9344\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9818\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9895\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "mnist_classification_model\\variables is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m model\u001b[39m.\u001b[39mfit(dataset, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, callbacks\u001b[39m=\u001b[39m[tensorboard_callback])\n\u001b[0;32m     39\u001b[0m \u001b[39m# Save the model for future use if needed.\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m model\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39mmnist_classification_model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Start TensorBoard with the following command:\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m# tensorboard --logdir logs/fit\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Alan de Castro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.makedirs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[0;32m    503\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[39m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mRecursivelyCreateDir(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: mnist_classification_model\\variables is not a directory"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Prepare a dataset.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Instantiate a simple classification model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(256, activation=tf.nn.relu),\n",
    "  layers.Dense(256, activation=tf.nn.relu),\n",
    "  layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Instantiate a logistic loss function that expects integer targets.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Instantiate an accuracy metric.\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Create a log directory for TensorBoard.\n",
    "log_dir = \"logs1/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])\n",
    "\n",
    "# Train the model with TensorBoard callback.\n",
    "model.fit(dataset, epochs=5, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Save the model for future use if needed.\n",
    "model.save(\"mnist_classification_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19264), started 21:33:14 ago. (Use '!kill 19264' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4025611b74f5a51c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4025611b74f5a51c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs1/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
